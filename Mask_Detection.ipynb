{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8xUXbPnN_SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "bae50e71-60cb-4f7b-fc3f-b14b0ecd92e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "print(os.listdir('/content/gdrive/My Drive/face_mask-dataset'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "['train', 'valid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx_AAibwQ7CP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aafd6c56-cbd2-4a59-ec02-5bf309c0a27e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import Model, Sequential, layers, models\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.optimizers import Adam\n",
        "from PIL import ImageFile\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e93w-VKDSctq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_width = 224 \n",
        "image_height = 224 \n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "initial_lr = 1e-4\n",
        "train_path = '/content/gdrive/My Drive/face_mask-dataset/train'\n",
        "valid_path = '/content/gdrive/My Drive/face_mask-dataset/valid'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIGBRN1RRTUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "783e53f4-12dc-460e-cf59-55bd49fc7e2e"
      },
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False,input_tensor= layers.Input(shape=(224,224,3)))\n",
        "head_model = base_model.output\n",
        "head_model = layers.AveragePooling2D((7,7))(head_model)\n",
        "head_model = layers.Flatten(name='Flatten')(head_model)\n",
        "head_model = layers.Dense(128,activation='relu')(head_model)\n",
        "head_model = layers.Dropout(0.5)(head_model)\n",
        "head_model = layers.Dense(2, activation='softmax')(head_model)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs= head_model)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "opt = Adam(learning_rate=initial_lr, decay = initial_lr/epochs)\n",
        "model.compile(loss='binary_crossentropy',optimizer= opt, metrics =['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ch-9JmSUUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ec05a740-3392-4788-cc8b-841047b6fbef"
      },
      "source": [
        "train_data_generator = ImageDataGenerator(\n",
        "    horizontal_flip = True, \n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range = 0.2, \n",
        "    height_shift_range = 0.2, \n",
        "    shear_range=0.15,\n",
        "    fill_mode = \"nearest\"\n",
        ")\n",
        "\n",
        "valid_data_generator = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")\n",
        "train_generator = train_data_generator.flow_from_directory(\n",
        "    train_path, \n",
        "    target_size = (image_width, image_width),\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "valid_generator = valid_data_generator.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size = (image_width, image_width),\n",
        "    class_mode = 'categorical'\n",
        "\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1101 images belonging to 2 classes.\n",
            "Found 275 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPMl1cX-ZNOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "3e0ba4cc-03c2-474f-9a95-d741d5c8c621"
      },
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch=552//batch_size,\n",
        "                    validation_data = valid_generator,\n",
        "                    validation_steps = 138//batch_size,\n",
        "                    epochs = 20\n",
        "                    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "17/17 [==============================] - 173s 10s/step - loss: 0.7458 - accuracy: 0.5956 - val_loss: 0.4154 - val_accuracy: 0.8438\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 141s 8s/step - loss: 0.5169 - accuracy: 0.7543 - val_loss: 0.1763 - val_accuracy: 0.8984\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 51s 3s/step - loss: 0.4573 - accuracy: 0.7776 - val_loss: 0.2611 - val_accuracy: 0.9478\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 42s 2s/step - loss: 0.3659 - accuracy: 0.8438 - val_loss: 0.2317 - val_accuracy: 0.8984\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 49s 3s/step - loss: 0.3125 - accuracy: 0.8603 - val_loss: 0.2665 - val_accuracy: 0.9652\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 42s 2s/step - loss: 0.2916 - accuracy: 0.8800 - val_loss: 0.2724 - val_accuracy: 0.9219\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 48s 3s/step - loss: 0.2885 - accuracy: 0.8724 - val_loss: 0.1610 - val_accuracy: 0.9478\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 43s 3s/step - loss: 0.2441 - accuracy: 0.8934 - val_loss: 0.1694 - val_accuracy: 0.8594\n",
            "Epoch 9/20\n",
            "17/17 [==============================] - 48s 3s/step - loss: 0.2349 - accuracy: 0.9062 - val_loss: 0.0781 - val_accuracy: 0.9913\n",
            "Epoch 10/20\n",
            "17/17 [==============================] - 44s 3s/step - loss: 0.2195 - accuracy: 0.9136 - val_loss: 0.1326 - val_accuracy: 0.9453\n",
            "Epoch 11/20\n",
            "17/17 [==============================] - 45s 3s/step - loss: 0.2068 - accuracy: 0.9170 - val_loss: 0.0954 - val_accuracy: 0.9766\n",
            "Epoch 12/20\n",
            "17/17 [==============================] - 45s 3s/step - loss: 0.2048 - accuracy: 0.9154 - val_loss: 0.0953 - val_accuracy: 0.9739\n",
            "Epoch 13/20\n",
            "17/17 [==============================] - 47s 3s/step - loss: 0.1651 - accuracy: 0.9371 - val_loss: 0.0814 - val_accuracy: 0.9531\n",
            "Epoch 14/20\n",
            "17/17 [==============================] - 45s 3s/step - loss: 0.1692 - accuracy: 0.9246 - val_loss: 0.1173 - val_accuracy: 0.9565\n",
            "Epoch 15/20\n",
            "17/17 [==============================] - 47s 3s/step - loss: 0.1712 - accuracy: 0.9357 - val_loss: 0.0645 - val_accuracy: 0.9766\n",
            "Epoch 16/20\n",
            "17/17 [==============================] - 44s 3s/step - loss: 0.1544 - accuracy: 0.9352 - val_loss: 0.0879 - val_accuracy: 0.9826\n",
            "Epoch 17/20\n",
            "17/17 [==============================] - 48s 3s/step - loss: 0.1359 - accuracy: 0.9504 - val_loss: 0.1014 - val_accuracy: 0.9766\n",
            "Epoch 18/20\n",
            "17/17 [==============================] - 44s 3s/step - loss: 0.1655 - accuracy: 0.9333 - val_loss: 0.0845 - val_accuracy: 0.9739\n",
            "Epoch 19/20\n",
            "17/17 [==============================] - 48s 3s/step - loss: 0.1824 - accuracy: 0.9320 - val_loss: 0.0442 - val_accuracy: 0.9922\n",
            "Epoch 20/20\n",
            "17/17 [==============================] - 46s 3s/step - loss: 0.1239 - accuracy: 0.9596 - val_loss: 0.0605 - val_accuracy: 0.9609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f319bd59e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsWqefLkYGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('face_mask_detection.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}